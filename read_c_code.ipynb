{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# CD Practical 1(B)\r\n",
    "### Implement Lexical Analyzer in Python and generate tokens for the given C code\r\n",
    "## Name: Yash Patel\r\n",
    "## Enrollement Number: 18162121024\r\n",
    "## Subject: Compiler Design"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "source": [
    "# re function is used to find the number of occurences of a substring in a string\r\n",
    "import re"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "source": [
    "# opening c file as read only mode\r\n",
    "file_input = open(\"c_code_input.c\", \"r\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "source": [
    "# Reading operations on C code\r\n",
    "\r\n",
    "operators = {\r\n",
    "    '+': 'add',\r\n",
    "    '-': 'sub',\r\n",
    "    '*': 'mul',\r\n",
    "    '/': 'div',\r\n",
    "    '%': 'mod',\r\n",
    "    '&': 'and',\r\n",
    "    '|': 'or',\r\n",
    "    '^': 'xor',\r\n",
    "    '<': 'lt',\r\n",
    "    '>': 'gt',\r\n",
    "    '==': 'eq',\r\n",
    "    '!=': 'ne',\r\n",
    "    '<=': 'le',\r\n",
    "    '>=': 'ge',\r\n",
    "    '&&': 'and',\r\n",
    "    '||': 'or',\r\n",
    "    '!': 'not',\r\n",
    "    '++': 'inc',\r\n",
    "    '--': 'dec',\r\n",
    "}\r\n",
    "optr_keys = operators.keys()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "source": [
    "# Reading comments in C code\r\n",
    "\r\n",
    "comments = {\r\n",
    "    '//': 'Single line comment',\r\n",
    "    '/*': 'Multi line Start',\r\n",
    "    '/*!': 'Multi line comment',\r\n",
    "    '*/': 'Multi line end',\r\n",
    "    '/**/' : 'Empty Multiline comment'\r\n",
    "}\r\n",
    "comment_keys = comments.keys()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "source": [
    "# Reading header in C code\r\n",
    "\r\n",
    "header = {\r\n",
    "    '.h': 'header',\r\n",
    "}\r\n",
    "header_keys = header.keys()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "source": [
    "# Reading sp_header_file in C code\r\n",
    "\r\n",
    "sp_header_file = {\r\n",
    "    '<stdio.h>': 'Standart Input/Output header',\r\n",
    "    '<stdlib.h>': 'Standart Library header',\r\n",
    "    '<string.h>': 'Standart String header',\r\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "source": [
    "# Reading macros in C code\r\n",
    "\r\n",
    "macros = {r'#\\w+' : 'macro'}\r\n",
    "macros_keys = macros.keys()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "source": [
    "# Reading datatypes from C code\r\n",
    "\r\n",
    "dataTypes = {\r\n",
    "    \"int\": \"int\",\r\n",
    "    \"char\": \"char\",\r\n",
    "    \"float\": \"float\",\r\n",
    "    \"double\": \"double\",\r\n",
    "    \"long\": \"long\",\r\n",
    "    \"short\": \"short\",\r\n",
    "    \"signed\": \"signed\",\r\n",
    "    \"void\": \"void\",\r\n",
    "    \"const\": \"const\",\r\n",
    "    \"float *\": \"float *\",\r\n",
    "    \"double *\": \"double *\",\r\n",
    "    'bool': 'bool',\r\n",
    "}\r\n",
    "datatype_keys = dataTypes.keys()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "source": [
    "# Reading keywords from C code\r\n",
    "\r\n",
    "keywords = {\r\n",
    "    'return': 'keyword that returns a value from a block'\r\n",
    "}\r\n",
    "keywords_keys = keywords.keys()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "source": [
    "# reading delimiters from c code\r\n",
    "\r\n",
    "delimiter = {\r\n",
    "    ';':'terminator symbol semicolon (;)'\r\n",
    "}\r\n",
    "delimiter_keys = delimiter.keys()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "source": [
    "# Reading blocks of C code\r\n",
    "\r\n",
    "blocks = {\r\n",
    "    '{' : 'Blocked Statement Body Open', \r\n",
    "    '}':'Blocked Statement Body Closed'\r\n",
    "}\r\n",
    "block_keys = blocks.keys()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "source": [
    "# Reading builtin_functions from c code\r\n",
    "\r\n",
    "builtin_functions = {\r\n",
    "    'printf':'printf prints its argument on the console'\r\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "source": [
    "# Reading non_identifiers from c code\r\n",
    "\r\n",
    "non_identifiers = ['_','-','+','/','*','`','~','!','@','#','$','%','^','&','*','(',')','=','|','\"',':',';','{'\r\n",
    ",'}','[',']','<','>','?','/']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "source": [
    "numerals = ['0','1','2','3','4','5','6','7','8','9','10']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "source": [
    "# Flags\r\n",
    "dataFlag = False"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "source": [
    "i = file_input.read()\r\n",
    "\r\n",
    "count = 0\r\n",
    "profram = i.split('\\n')\r\n",
    "\r\n",
    "for line in profram:\r\n",
    "    count = count + 1\r\n",
    "    print(\"Line #\", count, \"\\n\", line)\r\n",
    "\r\n",
    "    tokens = line.split(' ')\r\n",
    "    print(\"Tokens are\", tokens)\r\n",
    "    print(\"Line #\", count, \"properties \\n\")\r\n",
    "\r\n",
    "    for token in tokens:\r\n",
    "        if 'r' in token:\r\n",
    "            position = token.find('\\r')\r\n",
    "            token=token[:position]\r\n",
    "\r\n",
    "        if token in block_keys:\r\n",
    "            print(\"Found\", token, \"at position \", tokens.index(token))\r\n",
    "\r\n",
    "        if token in optr_keys:\r\n",
    "            print(\"Operator is: \", operators[token], \"at position \", tokens.index(token))\r\n",
    "\r\n",
    "        if token in comment_keys:\r\n",
    "            print(\"Comment Type: \", comments[token], \"at position \", tokens.index(token))\r\n",
    "\r\n",
    "        if token in macros_keys:\r\n",
    "            print(\"Macro is: \", macros[token], \"at position \", tokens.index(token))\r\n",
    "\r\n",
    "        if '.h' in token:\r\n",
    "            print(\"Header File is: \",token, sp_header_file[token], \"at position \", tokens.index(token), \"\\n\")\r\n",
    "\r\n",
    "        if '()' in token:\r\n",
    "            print(\"Function named\", token, \"at position \", tokens.index(token), \"\\n\")\r\n",
    "        \r\n",
    "        if dataFlag == True and (token not in non_identifiers) and ('()' not in token):\r\n",
    "            print(\"Identifier: \",token, \"at position \", tokens.index(token), \"\\n\", \"Data Flag is True\", \"\\n\")\r\n",
    "\r\n",
    "        if token in datatype_keys:\r\n",
    "            print(\"type is: \", dataTypes[token], \"at position \", tokens.index(token), \"\\n\")\r\n",
    "            dataFlag = True\r\n",
    "\r\n",
    "        if token in keywords_keys:\r\n",
    "            print(\"Keywords\", keywords[token], \"at position \", tokens.index(token), \"\\n\")\r\n",
    "\r\n",
    "        if token in delimiter:\r\n",
    "            print(\"Delimiter\" , delimiter[token], \"at position \", tokens.index(token), \"\\n\")\r\n",
    "\r\n",
    "        if '#' in token:\r\n",
    "            match = re.search(r'#\\w+', token)\r\n",
    "            print(\"Header\", match.group(), \"at position \", tokens.index(token), \"\\n\")\r\n",
    "\r\n",
    "        if token in numerals:\r\n",
    "            print(token,type(int(token)), \"at position \", tokens.index(token), \"\\n\")\r\n",
    "\r\n",
    "    dataFlag = False   \r\n",
    "\r\n",
    "    print(\"________________________\")\r\n",
    "file_input.close()\r\n",
    "\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Line # 1 \n",
      " // Lexical Analysis\n",
      "Tokens are ['//', 'Lexical', 'Analysis']\n",
      "Line # 1 properties \n",
      "\n",
      "Comment Type:  Single line comment at position  0\n",
      "________________________\n",
      "Line # 1 \n",
      " /* Program */\n",
      "Tokens are ['/*', 'Program', '*/']\n",
      "Line # 1 properties \n",
      "\n",
      "Comment Type:  Multi line Start at position  0\n",
      "Comment Type:  Multi line end at position  2\n",
      "________________________\n",
      "Line # 1 \n",
      " #include <stdio.h> // This is a header file\n",
      "Tokens are ['#include', '<stdio.h>', '//', 'This', 'is', 'a', 'header', 'file']\n",
      "Line # 1 properties \n",
      "\n",
      "Header #include at position  0 \n",
      "\n",
      "Header File is:  <stdio.h> Standart Input/Output header at position  1 \n",
      "\n",
      "Comment Type:  Single line comment at position  2\n",
      "________________________\n",
      "Line # 1 \n",
      " int main()\n",
      "Tokens are ['int', 'main()']\n",
      "Line # 1 properties \n",
      "\n",
      "type is:  int at position  0 \n",
      "\n",
      "Function named main() at position  1 \n",
      "\n",
      "________________________\n",
      "Line # 1 \n",
      " {\n",
      "Tokens are ['{']\n",
      "Line # 1 properties \n",
      "\n",
      "Found { at position  0\n",
      "________________________\n",
      "Line # 1 \n",
      "     int a,b,c,d;\n",
      "Tokens are ['', '', '', '', 'int', 'a,b,c,d;']\n",
      "Line # 1 properties \n",
      "\n",
      "type is:  int at position  4 \n",
      "\n",
      "Identifier:  a,b,c,d; at position  5 \n",
      " Data Flag is True \n",
      "\n",
      "________________________\n",
      "Line # 1 \n",
      "     a=10;\n",
      "Tokens are ['', '', '', '', 'a=10;']\n",
      "Line # 1 properties \n",
      "\n",
      "________________________\n",
      "Line # 1 \n",
      "     printf(\"The value of a is %d \",a);\n",
      "Tokens are ['', '', '', '', 'printf(\"The', 'value', 'of', 'a', 'is', '%d', '\",a);']\n",
      "Line # 1 properties \n",
      "\n",
      "________________________\n",
      "Line # 1 \n",
      "     return 0;\n",
      "Tokens are ['', '', '', '', 'return', '0;']\n",
      "Line # 1 properties \n",
      "\n",
      "________________________\n",
      "Line # 1 \n",
      " }\n",
      "Tokens are ['}']\n",
      "Line # 1 properties \n",
      "\n",
      "Found } at position  0\n",
      "________________________\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit"
  },
  "interpreter": {
   "hash": "40832b828c3f99a475ec6e85c89fa74659940f9f29571298adeb628817a03902"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
